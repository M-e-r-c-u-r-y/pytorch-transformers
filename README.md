# PyTorch Seq2Seq

This repo contains tutorials covering transformer models using [PyTorch](https://github.com/pytorch/pytorch) 1.4 and [TorchText](https://github.com/pytorch/text) 0.5 using Python 3.6.

**If you find any mistakes with the code, please do not hesitate to submit an issue. I welcome any feedback, positive or negative!**

## Getting Started

To install PyTorch, see installation instructions on the [PyTorch website](pytorch.org).

To install TorchText:

``` bash
pip install torchtext
```

We'll also make use of spaCy to tokenize our data. To install spaCy, follow the instructions [here](https://spacy.io/usage/) making sure to install both the English and German models with:

``` bash
python -m spacy download en
python -m spacy download de
```

## Tutorials


## References

Here are some things I looked at while making these tutorials. Some of it may be out of date.

- https://github.com/bentrevett/pytorch-seq2seq
